{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RJ_assignment_regression_classification_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rileythejones/DS-Unit-2-Linear-Models/blob/master/RJ_assignment_regression_classification_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwocFOJAKyz-",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Ridge Regression\n",
        "\n",
        "## Assignment\n",
        "\n",
        "We're going back to our other **New York City** real estate dataset. Instead of predicting apartment rents, you'll predict property sales prices.\n",
        "\n",
        "But not just for condos in Tribeca...\n",
        "\n",
        "Instead, predict property sales prices for **One Family Dwellings** (`BUILDING_CLASS_CATEGORY` == `'01 ONE FAMILY DWELLINGS'`). \n",
        "\n",
        "Use a subset of the data where the **sale price was more than \\\\$100 thousand and less than $2 million.** \n",
        "\n",
        "The [NYC Department of Finance](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page) has a glossary of property sales terms and NYC Building Class Code Descriptions. The data comes from the [NYC OpenData](https://data.cityofnewyork.us/browse?q=NYC%20calendar%20sales) portal.\n",
        "\n",
        "- [ ] Do train/test split. Use data from January â€”Â March 2019 to train. Use data from April 2019 to test.\n",
        "- [ ] Do one-hot encoding of categorical features.\n",
        "- [ ] Do feature selection with `SelectKBest`.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Fit a ridge regression model with multiple features.\n",
        "- [ ] Get mean absolute error for the test set.\n",
        "- [ ] As always, commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Instead of `Ridge`, try `LinearRegression`. Depending on how many features you select, your errors will probably blow up! ðŸ’¥\n",
        "- [ ] Instead of `Ridge`, try [`RidgeCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html).\n",
        "- [ ] Learn more about feature selection:\n",
        "    - [\"Permutation importance\"](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "    - [scikit-learn's User Guide for Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "    - [mlxtend](http://rasbt.github.io/mlxtend/) library\n",
        "    - scikit-learn-contrib libraries: [boruta_py](https://github.com/scikit-learn-contrib/boruta_py) & [stability-selection](https://github.com/scikit-learn-contrib/stability-selection)\n",
        "    - [_Feature Engineering and Selection_](http://www.feat.engineering/) by Kuhn & Johnson.\n",
        "- [ ] Try [statsmodels](https://www.statsmodels.org/stable/index.html) if youâ€™re interested in more inferential statistical approach to linear regression and feature selection, looking at p values and 95% confidence intervals for the coefficients.\n",
        "- [ ] Read [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapters 1-3, for more math & theory, but in an accessible, readable way.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'\n",
        "    \n",
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJBD4ruICm1m",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read New York City property sales data\n",
        "df = pd.read_csv(DATA_PATH+'condos/NYC_Citywide_Rolling_Calendar_Sales.csv')\n",
        "\n",
        "# Change column names: replace spaces with underscores\n",
        "df.columns = [col.replace(' ', '_') for col in df]\n",
        "\n",
        "# SALE_PRICE was read as strings.\n",
        "# Remove symbols, convert to integer\n",
        "df['SALE_PRICE'] = (\n",
        "    df['SALE_PRICE']\n",
        "    .str.replace('$','')\n",
        "    .str.replace('-','')\n",
        "    .str.replace(',','')\n",
        "    .astype(int)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-uawqS_Ky0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BOROUGH is a numeric column, but arguably should be a categorical feature,\n",
        "# so convert it from a number to a string\n",
        "df['BOROUGH'] = df['BOROUGH'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdFR4fl0Ky0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduce cardinality for NEIGHBORHOOD feature\n",
        "\n",
        "# Get a list of the top 10 neighborhoods\n",
        "top10 = df['NEIGHBORHOOD'].value_counts()[:10].index\n",
        "\n",
        "# At locations where the neighborhood is NOT in the top 10, \n",
        "# replace the neighborhood with 'OTHER'\n",
        "df.loc[~df['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETaoNi5-vy-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame([[1, 3, 4, 5]], columns=['A', 'B', 'C', 'D'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6104cqoFwObJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "1c6e8675-1a4d-40de-81cb-5f003e88817f"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   A  B  C  D\n",
              "0  1  3  4  5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoEdVlDZvtWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a58cc48f-d726-489e-f775-7aedda71d130"
      },
      "source": [
        "!pip install pandas_profiling"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_profiling in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: jinja2>=2.8 in /usr/local/lib/python3.6/dist-packages (from pandas_profiling) (2.10.3)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from pandas_profiling) (0.25.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from pandas_profiling) (1.12.0)\n",
            "Requirement already satisfied: matplotlib>=1.4 in /usr/local/lib/python3.6/dist-packages (from pandas_profiling) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.8->pandas_profiling) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pandas_profiling) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pandas_profiling) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pandas_profiling) (1.17.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas_profiling) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas_profiling) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas_profiling) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4->pandas_profiling) (41.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppm9qkGRKy0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.profile_report()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypjkTE34x9Aa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "ce81c30a-8846-47c7-af08-5c9b1ec7fd8c"
      },
      "source": [
        "profile = pandas_profiling.ProfileReport(df1)\n",
        "print(profile)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9adf0f80c079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfileReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pandas_profiling' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnarg9PC2ZtG",
        "colab_type": "text"
      },
      "source": [
        "Do train/test split. Use data from January â€” March 2019 to train. Use data from April 2019 to test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq18zBSbxyAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train \n",
        "test\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ3SirbM5WWg",
        "colab_type": "text"
      },
      "source": [
        " Do one-hot encoding of categorical features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhpopsAK5S3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "X_test = encoder.transform(X_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuHJTEGR5Xvz",
        "colab_type": "text"
      },
      "source": [
        " Do feature selection with SelectKBest.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofXWp8tA5Ub9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.feature_selection import f_regression, SelectKBest\n",
        "selector = SelectKBest(score_func=f_regression, k=15)\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "X_train_selected.shape, X_test_selected.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r5flX-f5PlI",
        "colab_type": "text"
      },
      "source": [
        " Do feature scaling.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAGfpA9Z5OdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "boston = load_boston()\n",
        "boston.data = scale(boston.data)  # Very helpful for regularization!\n",
        "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "df['Price'] = boston.target\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K4nsSxR2cy3",
        "colab_type": "text"
      },
      "source": [
        "Fit a ridge regression model with MULTIPLE features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLu1I5R6yIiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_reg = Ridge().fit(X, y)\n",
        "mean_squared_error(y, ridge_reg.predict(X))\n",
        "\n",
        "alphas = []\n",
        "mses = []\n",
        "\n",
        "for alpha in range(0, 200, 1):\n",
        "    ridge_reg_split = Ridge(alpha=alpha).fit(X_train, y_train)\n",
        "    mse = mean_squared_error(y_test, ridge_reg_split.predict(X_test))\n",
        "    print(alpha, mse)\n",
        "    alphas.append(alpha)\n",
        "    mses.append(mse)\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(alphas, mses);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIfKFTxl2eXX",
        "colab_type": "text"
      },
      "source": [
        "Get mean absolute error for the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UibukQ6Qy4tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "for k in range(1, len(X_train.columns)+1): # add one to be inclusive to make 32\n",
        "    \n",
        "    print(f'{k} features')\n",
        "    \n",
        "    selector = SelectKBest(score_func=f_regression, k=k)\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "    \n",
        "    model = Ridge()\n",
        "    model.fit(X_train_selected, y_train)\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    \n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    print(f'Test Mean Absolute Error: ${mae:,.0f} \\n')\n",
        "    print(features[k]) # my code "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xlmQUQp2VnF",
        "colab_type": "text"
      },
      "source": [
        "fit transform and then transform on the training and test set respectively. this works with PCA somehow. It remembers the same transformtion that was done on the training set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2--l1Iz0zYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# avoid overfitting by dimensionality reduction, train/test split, PCA vs. select k-best\n",
        "# choosing the right value of alpha is similar to choosing the right value of K\n",
        "# it's being empirical rather than being theoretical. \n",
        "# Guess and check, tinkering \n",
        "\n",
        "# alpha and for loop\n",
        "# some regularization minimizes error without adding too much bias \n",
        "\n",
        "# RidgeCV saves you from having to write the for loop or fancier ways of cross validation\n",
        "# Stretch goal ^^^"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjlEbAf-2hB_",
        "colab_type": "text"
      },
      "source": [
        "As always, commit your notebook to your fork of the GitHub repo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0uwRIsUyvTR",
        "colab_type": "text"
      },
      "source": [
        "Add your own stretch goal(s) !\n",
        " Instead of Ridge, try LinearRegression. Depending on how many features you select, your errors will probably blow up! ðŸ’¥\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5wnU86NyyKh",
        "colab_type": "text"
      },
      "source": [
        " Instead of Ridge, try RidgeCV.\n",
        " Learn more about feature selection:\n",
        "\"Permutation importance\"\n",
        "scikit-learn's User Guide for Feature Selection\n",
        "mlxtend library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUZwJJJQy3we",
        "colab_type": "text"
      },
      "source": [
        "scikit-learn-contrib libraries: boruta_py & stability-selection\n",
        "Feature Engineering and Selection by Kuhn & Johnson.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmRQ1xfcy6l0",
        "colab_type": "text"
      },
      "source": [
        " Try statsmodels if youâ€™re interested in more inferential statistical approach to linear regression and feature selection, looking at p values and 95% confidence intervals for the coefficients.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5yaRvtgy8Jv",
        "colab_type": "text"
      },
      "source": [
        " Read An Introduction to Statistical Learning, Chapters 1-3, for more math & theory, but in an accessible, readable way.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8IjNV_-y-QM",
        "colab_type": "text"
      },
      "source": [
        "Try scikit-learn pipelines."
      ]
    }
  ]
}